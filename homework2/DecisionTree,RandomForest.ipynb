{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "928e29d0-74bf-4adc-9190-7fc175256f26",
   "metadata": {},
   "source": [
    "# Введение в машинное обучение для Java-разработчиков\n",
    "### Практическое задание 2.  Деревья решений, случайный лес.\n",
    "### Дата выдачи: 26.10.2023\n",
    "\n",
    "### Дедлайн: 23:59MSK 08.11.2023\n",
    "\n",
    "## О задании\n",
    "В этом задании мы попытаемся разобраться в устройстве деревьев решений и ансамбля на основе деревьев. \n",
    "\n",
    "## Оценивание и штрафы\n",
    "Каждая из задач (помечены тегом [task]) имеет определенное количество баллов (указана в скобках около задачи). Максимально допустимая оценка за работу — 15 баллов. \n",
    "\n",
    "- от 4 до 8 баллов - оценка \"3\"\n",
    "- от 8 до 14 баллов - оценка \"4\"\n",
    "- 15 баллов - оценка \"5\"\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов, что автоматически ведет к несдаче курса. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в комментариях. \n",
    "В данном задании есть необязательные бонусные задания, выполнение которых добавляет баллы в карму :)\n",
    "\n",
    "## Формат сдачи\n",
    "Задания сдаются путем форка основного репозитория, коммита решения в мастер-ветку вашего форка и оповещении преподавателя о выполнении ДЗ. \n",
    "\n",
    "Для удобства проверки самостоятельно посчитайте свою максимальную оценку (исходя из набора решенных задач) и укажите ниже.\n",
    "\n",
    "[[Укажите количество набранных баллов]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baea62d-018e-48c0-bc80-1de460f4472d",
   "metadata": {},
   "source": [
    "## Часть 1. Дерево решений\n",
    "\n",
    "- [task] Реализуйте подбор признака и порога для поиска условия разбиения выборки методом перебора (2 балла)\n",
    "- [task] Реализуйте метод predict для инференса дерева на датасете (1 балл)\n",
    "- [task] Обучите дерево на датасете ирисов Фишера (1 балл)\n",
    "- Бонусное задание: В методе `_calculate_leaf_value` возвращайте вероятность классов\n",
    "- Бонусное задание: Замените критерий Джини на энтропийный критерий\n",
    "4 балла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5cf154b-80bc-4dc4-9580-edfd099ea98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class DecisionNode:\n",
    "    def __init__(self, feature=None, threshold=None, value=None, true_branch=None, false_branch=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.value = value\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=5):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build_tree(X, y)\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        if depth == self.max_depth or len(y) < self.min_samples_split:\n",
    "            return DecisionNode(value=self._calculate_leaf_value(y))\n",
    "\n",
    "        best_feature, best_threshold = self._find_best_split(X, y)\n",
    "        if best_feature is None or best_threshold is None:\n",
    "            return DecisionNode(value=self._calculate_leaf_value(y))\n",
    "\n",
    "        mask = X[:, best_feature] <= best_threshold\n",
    "        true_branch = self._build_tree(X[mask], y[mask], depth + 1)\n",
    "        false_branch = self._build_tree(X[~mask], y[~mask], depth + 1)\n",
    "\n",
    "        return DecisionNode(feature=best_feature, threshold=best_threshold, true_branch=true_branch, false_branch=false_branch)\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_gain = 0\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            curXColumn = X[:, i]\n",
    "            cur_gain, cur_threshold =  self._find_best_split_on_column(curXColumn, y)\n",
    "\n",
    "            if cur_gain > best_gain:\n",
    "                best_gain = cur_gain\n",
    "                best_feature = i\n",
    "                best_threshold = cur_threshold\n",
    "            \n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _split_y(self, x_column, y_values, x_split_value):\n",
    "        y_true = [y for idx, element in enumerate(x_column) if element <= x_split_value for y in [y_values[idx]]]\n",
    "        y_false = [y for idx, element in enumerate(x_column) if element > x_split_value for y in [y_values[idx]]]\n",
    "        return y_true, y_false\n",
    "\n",
    "    def _find_best_split_on_column(self, x_column, y_values):\n",
    "        column_best_gain = 0\n",
    "        column_best_threshold = None\n",
    "        for idx, element in enumerate(x_column):\n",
    "            y_true, y_false = self._split_y(x_column, y_values, element)\n",
    "            cur_gain = self._calculate_gain(y_values, y_true ,y_false)\n",
    "            if column_best_gain < cur_gain:\n",
    "                column_best_gain = cur_gain\n",
    "                column_best_threshold = element\n",
    "        return column_best_gain, column_best_threshold\n",
    "\n",
    "    def _calculate_gain(self, y, y_true, y_false):\n",
    "        p = len(y_true) / len(y)\n",
    "        impurity_before = self._gini_impurity(y)\n",
    "        impurity_after = p * self._gini_impurity(y_true) + (1 - p) * self._gini_impurity(y_false)\n",
    "        return impurity_before - impurity_after\n",
    "\n",
    "    def _gini_impurity(self, y):\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "    def _calculate_leaf_value(self, y):\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        most_common_class = classes[np.argmax(counts)]\n",
    "        return most_common_class\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "\n",
    "        for arr in X:\n",
    "            predictions.append(self._next_node(self.root, arr))\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def _next_node(self, node, x):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "            \n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._next_node(node.true_branch, x)\n",
    "        else:\n",
    "            return self._next_node(node.false_branch, x)\n",
    "        \n",
    "        \n",
    "def print_tree(node, depth=0):\n",
    "    indent = \"    \" * depth\n",
    "    if node.value is not None:\n",
    "        print(indent + \"Predicted value:\", node.value)\n",
    "    else:\n",
    "        print(indent + \"Feature\", node.feature, \"<=\", node.threshold)\n",
    "        print(indent + \"--> True:\")\n",
    "        print_tree(node.true_branch, depth + 1)\n",
    "        print(indent + \"--> False:\")\n",
    "        print_tree(node.false_branch, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb7232b0-bbdb-4bfb-b511-d9ea51d0273c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_new  y\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n"
     ]
    }
   ],
   "source": [
    "data = load_iris(as_frame=True)\n",
    "X = data[\"data\"].values\n",
    "y = data[\"target\"].values\n",
    "\n",
    "tree = DecisionTree()\n",
    "tree.fit(X, y)\n",
    "y_new = tree.predict(X)\n",
    "\n",
    "print('y_new  y')\n",
    "for i in range(len(y)):\n",
    "    print(y_new[i], y[i], sep='      ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b0b8b0-1e45-427a-807b-139f33982976",
   "metadata": {},
   "source": [
    "### Часть 2. Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e052b110-f73b-4440-801a-09787d8f2808",
   "metadata": {},
   "source": [
    "##### [task] 1. Усреднение классификаторов (2 балла)\n",
    "Реализуйте бэггинг над решающими деревьями (усреднение предсказанных вероятностей всего ансамбля или путем \"голосования\"). В качестве базового алгоритма используйте либо наш класс или DecisionTreeClassifier из пакета scikit-learn. \n",
    "\n",
    "##### [task] 2. Бутстрап обучающей выборки (2 балла)\n",
    "Добавим к нашему усреднению предсказаний бутстрап выборки (генерация случайной выборки того же размера с возвращением). Сгенерируйте с помощью него отдельную обучающую выборку для каждого дерева, обучите их и усредните предсказания, как в предыдущем пункте.\n",
    "\n",
    "##### [task] 3. Выбор случайного подмножества признаков при построении нового дерева. (2 балла)\n",
    "Обучайте каждое дерево на отдельной бутстрап-выборке и случайно выбирайте признаки для обучения. \n",
    "\n",
    "##### [task] 4. Подсчитайте метрики оценки качества классификации (accuracy, precision, recall, ROC AUC, F-мера) для каждого из вариантов дерева. Сделайте отдельную функцию для подсчета метрик (1 балл)\n",
    "\n",
    "- Используемый датасет https://archive.ics.uci.edu/dataset/94/spambase\n",
    "- Все гиперпараметры необходимо вынести аргументы соответсвующей функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a25dbc-8f9d-49aa-93b2-79738df7731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.3-py3-none-any.whl (7.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.3\n",
      "{'uci_id': 94, 'name': 'Spambase', 'repository_url': 'https://archive.ics.uci.edu/dataset/94/spambase', 'data_url': 'https://archive.ics.uci.edu/static/public/94/data.csv', 'abstract': 'Classifying Email as Spam or Non-Spam', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 4601, 'num_features': 57, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1999, 'last_updated': 'Mon Aug 28 2023', 'dataset_doi': '10.24432/C53G6X', 'creators': ['Mark Hopkins', 'Erik Reeber', 'George Forman', 'Jaap Suermondt'], 'intro_paper': None, 'additional_info': {'summary': 'The \"spam\" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...\\n\\nThe classification task for this dataset is to determine whether a given email is spam or not.\\n\\t\\nOur collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word \\'george\\' and the area code \\'650\\' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.\\n\\nFor background on spam: Cranor, Lorrie F., LaMacchia, Brian A.  Spam!, Communications of the ACM, 41(8):74-83, 1998.\\n\\nTypical performance is around ~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter. See also Hewlett-Packard Internal-only Technical Report. External version forthcoming. ', 'purpose': None, 'funded_by': None, 'instances_represent': 'Emails', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'The last column of \\'spambase.data\\' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail.  The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  For the statistical measures of each attribute, see the end of this file.  Here are the definitions of the attributes:\\r\\n\\r\\n48 continuous real [0,100] attributes of type word_freq_WORD \\r\\n= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.\\r\\n\\r\\n6 continuous real [0,100] attributes of type char_freq_CHAR] \\r\\n= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\\r\\n\\r\\n1 continuous real [1,...] attribute of type capital_run_length_average \\r\\n= average length of uninterrupted sequences of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_longest \\r\\n= length of longest uninterrupted sequence of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_total \\r\\n= sum of length of uninterrupted sequences of capital letters \\r\\n= total number of capital letters in the e-mail\\r\\n\\r\\n1 nominal {0,1} class attribute of type spam\\r\\n= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \\r\\n', 'citation': None}}\n",
      "                          name     role        type demographic  \\\n",
      "0               word_freq_make  Feature  Continuous        None   \n",
      "1            word_freq_address  Feature  Continuous        None   \n",
      "2                word_freq_all  Feature  Continuous        None   \n",
      "3                 word_freq_3d  Feature  Continuous        None   \n",
      "4                word_freq_our  Feature  Continuous        None   \n",
      "5               word_freq_over  Feature  Continuous        None   \n",
      "6             word_freq_remove  Feature  Continuous        None   \n",
      "7           word_freq_internet  Feature  Continuous        None   \n",
      "8              word_freq_order  Feature  Continuous        None   \n",
      "9               word_freq_mail  Feature  Continuous        None   \n",
      "10           word_freq_receive  Feature  Continuous        None   \n",
      "11              word_freq_will  Feature  Continuous        None   \n",
      "12            word_freq_people  Feature  Continuous        None   \n",
      "13            word_freq_report  Feature  Continuous        None   \n",
      "14         word_freq_addresses  Feature  Continuous        None   \n",
      "15              word_freq_free  Feature  Continuous        None   \n",
      "16          word_freq_business  Feature  Continuous        None   \n",
      "17             word_freq_email  Feature  Continuous        None   \n",
      "18               word_freq_you  Feature  Continuous        None   \n",
      "19            word_freq_credit  Feature  Continuous        None   \n",
      "20              word_freq_your  Feature  Continuous        None   \n",
      "21              word_freq_font  Feature  Continuous        None   \n",
      "22               word_freq_000  Feature  Continuous        None   \n",
      "23             word_freq_money  Feature  Continuous        None   \n",
      "24                word_freq_hp  Feature  Continuous        None   \n",
      "25               word_freq_hpl  Feature  Continuous        None   \n",
      "26            word_freq_george  Feature  Continuous        None   \n",
      "27               word_freq_650  Feature  Continuous        None   \n",
      "28               word_freq_lab  Feature  Continuous        None   \n",
      "29              word_freq_labs  Feature  Continuous        None   \n",
      "30            word_freq_telnet  Feature  Continuous        None   \n",
      "31               word_freq_857  Feature  Continuous        None   \n",
      "32              word_freq_data  Feature  Continuous        None   \n",
      "33               word_freq_415  Feature  Continuous        None   \n",
      "34                word_freq_85  Feature  Continuous        None   \n",
      "35        word_freq_technology  Feature  Continuous        None   \n",
      "36              word_freq_1999  Feature  Continuous        None   \n",
      "37             word_freq_parts  Feature  Continuous        None   \n",
      "38                word_freq_pm  Feature  Continuous        None   \n",
      "39            word_freq_direct  Feature  Continuous        None   \n",
      "40                word_freq_cs  Feature  Continuous        None   \n",
      "41           word_freq_meeting  Feature  Continuous        None   \n",
      "42          word_freq_original  Feature  Continuous        None   \n",
      "43           word_freq_project  Feature  Continuous        None   \n",
      "44                word_freq_re  Feature  Continuous        None   \n",
      "45               word_freq_edu  Feature  Continuous        None   \n",
      "46             word_freq_table  Feature  Continuous        None   \n",
      "47        word_freq_conference  Feature  Continuous        None   \n",
      "48                 char_freq_;  Feature  Continuous        None   \n",
      "49                 char_freq_(  Feature  Continuous        None   \n",
      "50                 char_freq_[  Feature  Continuous        None   \n",
      "51                 char_freq_!  Feature  Continuous        None   \n",
      "52                 char_freq_$  Feature  Continuous        None   \n",
      "53                 char_freq_#  Feature  Continuous        None   \n",
      "54  capital_run_length_average  Feature  Continuous        None   \n",
      "55  capital_run_length_longest  Feature  Continuous        None   \n",
      "56    capital_run_length_total  Feature  Continuous        None   \n",
      "57                       Class   Target      Binary        None   \n",
      "\n",
      "                 description units missing_values  \n",
      "0                       None  None             no  \n",
      "1                       None  None             no  \n",
      "2                       None  None             no  \n",
      "3                       None  None             no  \n",
      "4                       None  None             no  \n",
      "5                       None  None             no  \n",
      "6                       None  None             no  \n",
      "7                       None  None             no  \n",
      "8                       None  None             no  \n",
      "9                       None  None             no  \n",
      "10                      None  None             no  \n",
      "11                      None  None             no  \n",
      "12                      None  None             no  \n",
      "13                      None  None             no  \n",
      "14                      None  None             no  \n",
      "15                      None  None             no  \n",
      "16                      None  None             no  \n",
      "17                      None  None             no  \n",
      "18                      None  None             no  \n",
      "19                      None  None             no  \n",
      "20                      None  None             no  \n",
      "21                      None  None             no  \n",
      "22                      None  None             no  \n",
      "23                      None  None             no  \n",
      "24                      None  None             no  \n",
      "25                      None  None             no  \n",
      "26                      None  None             no  \n",
      "27                      None  None             no  \n",
      "28                      None  None             no  \n",
      "29                      None  None             no  \n",
      "30                      None  None             no  \n",
      "31                      None  None             no  \n",
      "32                      None  None             no  \n",
      "33                      None  None             no  \n",
      "34                      None  None             no  \n",
      "35                      None  None             no  \n",
      "36                      None  None             no  \n",
      "37                      None  None             no  \n",
      "38                      None  None             no  \n",
      "39                      None  None             no  \n",
      "40                      None  None             no  \n",
      "41                      None  None             no  \n",
      "42                      None  None             no  \n",
      "43                      None  None             no  \n",
      "44                      None  None             no  \n",
      "45                      None  None             no  \n",
      "46                      None  None             no  \n",
      "47                      None  None             no  \n",
      "48                      None  None             no  \n",
      "49                      None  None             no  \n",
      "50                      None  None             no  \n",
      "51                      None  None             no  \n",
      "52                      None  None             no  \n",
      "53                      None  None             no  \n",
      "54                      None  None             no  \n",
      "55                      None  None             no  \n",
      "56                      None  None             no  \n",
      "57  spam (1) or not spam (0)  None             no  \n"
     ]
    }
   ],
   "source": [
    "# fetch dataset \n",
    "!pip install ucimlrepo\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "spambase = fetch_ucirepo(id=94) \n",
    "  \n",
    "# data (as numpy arrays) \n",
    "X = spambase.data.features.values\n",
    "y = spambase.data.targets.values\n",
    "  \n",
    "# metadata \n",
    "print(spambase.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(spambase.variables)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0fc3acb-912a-40ee-9eb0-b944bd9cccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/miniconda3/envs/introToML/lib/python3.11/site-packages/sklearn/ensemble/_bagging.py:802: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [1]\n",
      "1      [1]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [1]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [1]\n",
      "1      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [1]\n",
      "1      [1]\n",
      "1      [1]\n",
      "0      [0]\n",
      "0      [0]\n",
      "1      [0]\n",
      "0      [0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "base_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Создаем классификатор с использованием бэггинга и обучаем модель\n",
    "bagging_classifier = BaggingClassifier(base_classifier)\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    print(y_pred[i], y_test[i], sep='      ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07a7ea9d-4a14-43b4-8e8f-9be9d042cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def bootstrap_sample(X, y):\n",
    "    indices = resample(range(len(X)), replace=True)\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "# Количество деревьев\n",
    "n_estimators = 100\n",
    "# Список для хранения предсказаний каждого дерева\n",
    "predictions = []\n",
    "\n",
    "# Генерируем отдельную обучающую выборку и обучаем каждое дерево\n",
    "for i in range(n_estimators):\n",
    "    # Генерируем бутстрап выборку\n",
    "    X_boot, y_boot = bootstrap_sample(X_train, y_train)\n",
    "    \n",
    "    model = DecisionTreeRegressor()\n",
    "    # Обучаем модель на бутстрап выборке\n",
    "    model.fit(X_boot, y_boot)\n",
    "    # Делаем предсказание на тестовой выборке\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Сохраняем предсказания\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "# Усредняем предсказания всех деревьев\n",
    "ensemble_prediction = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0203333c-8490-4f79-8a34-241fb8717c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/miniconda3/envs/introToML/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 57 features, but RandomForestClassifier is expecting 7 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Добавление обученного дерева в список\u001b[39;00m\n\u001b[1;32m     43\u001b[0m trees\u001b[38;5;241m.\u001b[39mappend(tree)\n\u001b[0;32m---> 45\u001b[0m new_predict \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m accuracy, precision, recall, roc_auc, f1 \u001b[38;5;241m=\u001b[39m calculate_metrics(y_test, new_predict)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n",
      "File \u001b[0;32m~/miniconda3/envs/introToML/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    803\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    826\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/introToML/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    863\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    864\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    868\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/miniconda3/envs/introToML/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 599\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/introToML/lib/python3.11/site-packages/sklearn/base.py:626\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/introToML/lib/python3.11/site-packages/sklearn/base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 57 features, but RandomForestClassifier is expecting 7 features as input."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    roc_auc = roc_auc_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, roc_auc, f1\n",
    "\n",
    "trees = []\n",
    "num_trees = 100\n",
    "\n",
    "# Размер бутстрап-выборки (размер выборки с возвращением)\n",
    "bootstrap_size = int(0.8 * len(X_train))\n",
    "\n",
    "# Число случайно выбранных признаков для обучения каждого дерева\n",
    "num_features = int(np.sqrt(len(X_train[0])))\n",
    "\n",
    "\n",
    "\n",
    "# Обучение каждого дерева в случайном лесу\n",
    "for _ in range(num_trees):\n",
    "    # Создание бутстрап-выборки\n",
    "    bootstrap_indices = random.choices(range(len(X_train)), k=bootstrap_size)\n",
    "    X_bootstrap = X_train[bootstrap_indices]\n",
    "    y_bootstrap = y_train[bootstrap_indices]\n",
    "    \n",
    "    # Создание случайно выбранных признаков\n",
    "    random_features = random.sample(range(len(X_train[0])), num_features)\n",
    "    X_bootstrap = X_bootstrap[:, random_features]\n",
    "    \n",
    "    # Обучение дерева\n",
    "    tree = RandomForestClassifier()\n",
    "    tree.fit(X_bootstrap, y_bootstrap)\n",
    "    \n",
    "    # Добавление обученного дерева в список\n",
    "    trees.append(tree)\n",
    "\n",
    "    new_predict = tree.predict(X_test)\n",
    "    accuracy, precision, recall, roc_auc, f1 = calculate_metrics(y_test, new_predict)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"ROC AUC:\", roc_auc)\n",
    "    print(\"F1-score:\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab8f30f-8843-4fea-a88b-601e6933843c",
   "metadata": {},
   "source": [
    "#### Часть 3. \n",
    "\n",
    "- [task] Обучите RandomForestClassifier из sklearn на датасете из прошлой части (2 балла)\n",
    "- [task] Подсчитайте accuracy, precision, recall, ROC AUC, F-мера на отложенной выборке. Получилось лучше или хуже по сравнению с вашим вариантом RandomForest (2 балла)\n",
    "- Попробуйте объяснить результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e479d992-2f67-422b-9fe3-a703953e7084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/miniconda3/envs/introToML/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9522258414766558\n",
      "Recall: 0.9128205128205128\n",
      "Precision: 0.9726775956284153\n",
      "F1: 0.9417989417989417\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "my_predicts = classifier.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, my_predicts))\n",
    "print(\"Recall:\", recall_score(y_test, my_predicts))\n",
    "print(\"Precision:\", precision_score(y_test, my_predicts))\n",
    "print(\"F1:\", f1_score(y_test, my_predicts))\n",
    "print(\"ROC AUC\", roc_auc_score(true_labels, predicted_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0f368-c4b7-4a2d-8e9e-eb08af5f814c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
