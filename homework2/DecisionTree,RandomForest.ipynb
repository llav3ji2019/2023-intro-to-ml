{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "928e29d0-74bf-4adc-9190-7fc175256f26",
   "metadata": {},
   "source": [
    "# Введение в машинное обучение для Java-разработчиков\n",
    "### Практическое задание 2.  Деревья решений, случайный лес.\n",
    "### Дата выдачи: 26.10.2023\n",
    "\n",
    "### Дедлайн: 23:59MSK 08.11.2023\n",
    "\n",
    "## О задании\n",
    "В этом задании мы попытаемся разобраться в устройстве деревьев решений и ансамбля на основе деревьев. \n",
    "\n",
    "## Оценивание и штрафы\n",
    "Каждая из задач (помечены тегом [task]) имеет определенное количество баллов (указана в скобках около задачи). Максимально допустимая оценка за работу — 15 баллов. \n",
    "\n",
    "- от 4 до 8 баллов - оценка \"3\"\n",
    "- от 8 до 14 баллов - оценка \"4\"\n",
    "- 15 баллов - оценка \"5\"\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов, что автоматически ведет к несдаче курса. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в комментариях. \n",
    "В данном задании есть необязательные бонусные задания, выполнение которых добавляет баллы в карму :)\n",
    "\n",
    "## Формат сдачи\n",
    "Задания сдаются путем форка основного репозитория, коммита решения в мастер-ветку вашего форка и оповещении преподавателя о выполнении ДЗ. \n",
    "\n",
    "Для удобства проверки самостоятельно посчитайте свою максимальную оценку (исходя из набора решенных задач) и укажите ниже.\n",
    "\n",
    "[[Укажите количество набранных баллов]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baea62d-018e-48c0-bc80-1de460f4472d",
   "metadata": {},
   "source": [
    "## Часть 1. Дерево решений\n",
    "\n",
    "- [task] Реализуйте подбор признака и порога для поиска условия разбиения выборки методом перебора (2 балла)\n",
    "- [task] Реализуйте метод predict для инференса дерева на датасете (1 балл)\n",
    "- [task] Обучите дерево на датасете ирисов Фишера (1 балл)\n",
    "- Бонусное задание: В методе `_calculate_leaf_value` возвращайте вероятность классов\n",
    "- Бонусное задание: Замените критерий Джини на энтропийный критерий\n",
    "4 балла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b5cf154b-80bc-4dc4-9580-edfd099ea98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class DecisionNode:\n",
    "    def __init__(self, feature=None, threshold=None, value=None, true_branch=None, false_branch=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.value = value\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=5):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build_tree(X, y)\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        if depth == self.max_depth or len(y) < self.min_samples_split:\n",
    "            return DecisionNode(value=self._calculate_leaf_value(y))\n",
    "\n",
    "        best_feature, best_threshold = self._find_best_split(X, y)\n",
    "        if best_feature is None or best_threshold is None:\n",
    "            return DecisionNode(value=self._calculate_leaf_value(y))\n",
    "\n",
    "        mask = X[:, best_feature] <= best_threshold\n",
    "        true_branch = self._build_tree(X[mask], y[mask], depth + 1)\n",
    "        false_branch = self._build_tree(X[~mask], y[~mask], depth + 1)\n",
    "\n",
    "        return DecisionNode(feature=best_feature, threshold=best_threshold, true_branch=true_branch, false_branch=false_branch)\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_gain = 0\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            curXColumn = X[:, i]\n",
    "            cur_gain, cur_threshold =  self._find_best_split_on_column(curXColumn, y)\n",
    "\n",
    "            if cur_gain > best_gain:\n",
    "                best_gain = cur_gain\n",
    "                best_feature = i\n",
    "                best_threshold = cur_threshold\n",
    "            \n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _split_y(self, x_column, y_values, x_split_value):\n",
    "        y_true = [y for idx, element in enumerate(x_column) if element <= x_split_value for y in [y_values[idx]]]\n",
    "        y_false = [y for idx, element in enumerate(x_column) if element > x_split_value for y in [y_values[idx]]]\n",
    "        return y_true, y_false\n",
    "\n",
    "    def _find_best_split_on_column(self, x_column, y_values):\n",
    "        column_best_gain = 0\n",
    "        column_best_threshold = None\n",
    "        for idx, element in enumerate(x_column):\n",
    "            y_true, y_false = self._split_y(x_column, y_values, element)\n",
    "            cur_gain = self._calculate_gain(y_values, y_true ,y_false)\n",
    "            if column_best_gain < cur_gain:\n",
    "                column_best_gain = cur_gain\n",
    "                column_best_threshold = element\n",
    "        return column_best_gain, column_best_threshold\n",
    "\n",
    "    def _calculate_gain(self, y, y_true, y_false):\n",
    "        p = len(y_true) / len(y)\n",
    "        impurity_before = self._gini_impurity(y)\n",
    "        impurity_after = p * self._gini_impurity(y_true) + (1 - p) * self._gini_impurity(y_false)\n",
    "        return impurity_before - impurity_after\n",
    "\n",
    "    def _gini_impurity(self, y):\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "    def _calculate_leaf_value(self, y):\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        most_common_class = classes[np.argmax(counts)]\n",
    "        return most_common_class\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "\n",
    "        for arr in X:\n",
    "            predictions.append(self._next_node(self.root, arr))\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def _next_node(self, node, x):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "            \n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._next_node(node.true_branch, x)\n",
    "        else:\n",
    "            return self._next_node(node.false_branch, x)\n",
    "        \n",
    "        \n",
    "def print_tree(node, depth=0):\n",
    "    indent = \"    \" * depth\n",
    "    if node.value is not None:\n",
    "        print(indent + \"Predicted value:\", node.value)\n",
    "    else:\n",
    "        print(indent + \"Feature\", node.feature, \"<=\", node.threshold)\n",
    "        print(indent + \"--> True:\")\n",
    "        print_tree(node.true_branch, depth + 1)\n",
    "        print(indent + \"--> False:\")\n",
    "        print_tree(node.false_branch, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cb7232b0-bbdb-4bfb-b511-d9ea51d0273c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_new  y\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "0      0\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "1      1\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n",
      "2      2\n"
     ]
    }
   ],
   "source": [
    "data = load_iris(as_frame=True)\n",
    "X = data[\"data\"].values\n",
    "y = data[\"target\"].values\n",
    "\n",
    "tree = DecisionTree()\n",
    "tree.fit(X, y)\n",
    "y_new = tree.predict(X)\n",
    "\n",
    "print('y_new  y')\n",
    "for i in range(len(y)):\n",
    "    print(y_new[i], y[i], sep='      ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b0b8b0-1e45-427a-807b-139f33982976",
   "metadata": {},
   "source": [
    "### Часть 2. Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e052b110-f73b-4440-801a-09787d8f2808",
   "metadata": {},
   "source": [
    "##### [task] 1. Усреднение классификаторов (2 балла)\n",
    "Реализуйте бэггинг над решающими деревьями (усреднение предсказанных вероятностей всего ансамбля или путем \"голосования\"). В качестве базового алгоритма используйте либо наш класс или DecisionTreeClassifier из пакета scikit-learn. \n",
    "\n",
    "##### [task] 2. Бутстрап обучающей выборки (2 балла)\n",
    "Добавим к нашему усреднению предсказаний бутстрап выборки (генерация случайной выборки того же размера с возвращением). Сгенерируйте с помощью него отдельную обучающую выборку для каждого дерева, обучите их и усредните предсказания, как в предыдущем пункте.\n",
    "\n",
    "##### [task] 3. Выбор случайного подмножества признаков при построении нового дерева. (2 балла)\n",
    "Обучайте каждое дерево на отдельной бутстрап-выборке и случайно выбирайте признаки для обучения. \n",
    "\n",
    "##### [task] 4. Подсчитайте метрики оценки качества классификации (accuracy, precision, recall, ROC AUC, F-мера) для каждого из вариантов дерева. Сделайте отдельную функцию для подсчета метрик (1 балл)\n",
    "\n",
    "- Используемый датасет https://archive.ics.uci.edu/dataset/94/spambase\n",
    "- Все гиперпараметры необходимо вынести аргументы соответсвующей функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a25dbc-8f9d-49aa-93b2-79738df7731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "!pip install ucimlrepo\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "spambase = fetch_ucirepo(id=94) \n",
    "  \n",
    "# data (as numpy arrays) \n",
    "X = spambase.data.features.values\n",
    "y = spambase.data.targets.values\n",
    "  \n",
    "# metadata \n",
    "print(spambase.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(spambase.variables)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b0fc3acb-912a-40ee-9eb0-b944bd9cccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab8f30f-8843-4fea-a88b-601e6933843c",
   "metadata": {},
   "source": [
    "#### Часть 3. \n",
    "\n",
    "- [task] Обучите RandomForestClassifier из sklearn на датасете из прошлой части (2 балла)\n",
    "- [task] Подсчитайте accuracy, precision, recall, ROC AUC, F-мера на отложенной выборке. Получилось лучше или хуже по сравнению с вашим вариантом RandomForest (2 балла)\n",
    "- Попробуйте объяснить результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e479d992-2f67-422b-9fe3-a703953e7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
